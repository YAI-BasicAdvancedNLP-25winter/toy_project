{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:48:58.810863Z",
     "iopub.status.busy": "2025-03-02T13:48:58.810587Z",
     "iopub.status.idle": "2025-03-02T13:49:03.065383Z",
     "shell.execute_reply": "2025-03-02T13:49:03.064228Z",
     "shell.execute_reply.started": "2025-03-02T13:48:58.810833Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T14:58:16.613836Z",
     "iopub.status.busy": "2025-03-03T14:58:16.613397Z",
     "iopub.status.idle": "2025-03-03T14:58:16.622066Z",
     "shell.execute_reply": "2025-03-03T14:58:16.621107Z",
     "shell.execute_reply.started": "2025-03-03T14:58:16.613798Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETE\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "import re\n",
    "import sys\n",
    "import torch.optim as optim\n",
    "from transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import BertPreTrainedModel, BertModel, BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import time, json\n",
    "import datetime\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, random_split, Subset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support\n",
    "from collections import Counter\n",
    "import csv\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from transformers import AutoModel\n",
    "print(\"COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T14:58:17.293770Z",
     "iopub.status.busy": "2025-03-03T14:58:17.293439Z",
     "iopub.status.idle": "2025-03-03T14:58:17.322881Z",
     "shell.execute_reply": "2025-03-03T14:58:17.322187Z",
     "shell.execute_reply.started": "2025-03-03T14:58:17.293745Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETE\n"
     ]
    }
   ],
   "source": [
    "from transformers import BigBirdTokenizer\n",
    "from transformers import BigBirdModel\n",
    "import sentencepiece\n",
    "print(\"COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T14:58:17.815707Z",
     "iopub.status.busy": "2025-03-03T14:58:17.815257Z",
     "iopub.status.idle": "2025-03-03T14:58:18.552508Z",
     "shell.execute_reply": "2025-03-03T14:58:18.551490Z",
     "shell.execute_reply.started": "2025-03-03T14:58:17.815667Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def format_evidence(evidence):\n",
    "    full_text_list = [item['text'] for item in evidence.values()]\n",
    "    full_text = ' '.join(full_text_list)  # 띄어쓰기 유지하며 문자열 합치기\n",
    "    \n",
    "    # 문장 단위로 분할 (NLTK 활용)\n",
    "    sentences = nltk.sent_tokenize(full_text)\n",
    "    \n",
    "    # 너무 짧은 문장 제거 (5자 이하)\n",
    "    sentences = [s.strip() for s in sentences if len(s.strip()) > 5][:25]\n",
    "    \n",
    "    # 빈 리스트 예외 처리\n",
    "    if not sentences:\n",
    "        return ''\n",
    "    \n",
    "    return ' [SEP] '.join(sentences) + ' [SEP] '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T14:58:23.063702Z",
     "iopub.status.busy": "2025-03-03T14:58:23.063333Z",
     "iopub.status.idle": "2025-03-03T14:58:31.750100Z",
     "shell.execute_reply": "2025-03-03T14:58:31.749265Z",
     "shell.execute_reply.started": "2025-03-03T14:58:23.063668Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>news</th>\n",
       "      <th>extracted_entities</th>\n",
       "      <th>wiki_summary</th>\n",
       "      <th>wiki_full</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>news_merged</th>\n",
       "      <th>key sentences</th>\n",
       "      <th>key sentences explanation</th>\n",
       "      <th>summarized evidence sentences</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>u.s. senate republican leader mitch mcconnell ...</td>\n",
       "      <td>Mitch McConnell, Myanmar, Aung San Suu Kyi, Jo...</td>\n",
       "      <td>Mitch McConnell: Addison Mitchell McConnell II...</td>\n",
       "      <td>Mitch McConnell: Addison Mitchell McConnell II...</td>\n",
       "      <td>1</td>\n",
       "      <td>senate leader opposes lecturing myanmar leader...</td>\n",
       "      <td>title : senate leader opposes lecturing myanma...</td>\n",
       "      <td>[\"Mitch McConnell said on Tuesday he would not...</td>\n",
       "      <td>[\"McConnell's opposition to the resolution dir...</td>\n",
       "      <td>[\"Mitch McConnell is an American politician an...</td>\n",
       "      <td>[2, 3, 8, 6, 9, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>note little johnny might want consider use dia...</td>\n",
       "      <td>little johnny, isis, fort riley military base,...</td>\n",
       "      <td>little johnny: Little Johnny jokes are about a...</td>\n",
       "      <td>little johnny: Little Johnny jokes are about a...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>content : note little johnny might want consid...</td>\n",
       "      <td>[\"A 20-year-old Kansas man plotted to kill an ...</td>\n",
       "      <td>[\"This sentence supports the news because it p...</td>\n",
       "      <td>[\"Little Johnny jokes are about a small boy wh...</td>\n",
       "      <td>[13, 12, 29, 30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>president obama is clearly in good spirits tha...</td>\n",
       "      <td>president obama, republican party, trump presi...</td>\n",
       "      <td>president obama: Barack Hussein Obama II (born...</td>\n",
       "      <td>president obama: Barack Hussein Obama II (born...</td>\n",
       "      <td>0</td>\n",
       "      <td>president obama gets his troll game on by than...</td>\n",
       "      <td>title : president obama gets his troll game on...</td>\n",
       "      <td>[\"Obama said it was crucial for voters to oppo...</td>\n",
       "      <td>[\"This sentence supports the news because it e...</td>\n",
       "      <td>[\"President Obama is the 44th president of the...</td>\n",
       "      <td>[13, 14, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>a racist white woman in florida is surely furi...</td>\n",
       "      <td>Florida, Tallahassee, Trump, Martin Luther Kin...</td>\n",
       "      <td>Florida: Florida (  FLORR-ih-də; Spanish: [flo...</td>\n",
       "      <td>Florida: Florida (  FLORR-ih-də; Spanish: [flo...</td>\n",
       "      <td>0</td>\n",
       "      <td>racist florida woman tells black people you sh...</td>\n",
       "      <td>title : racist florida woman tells black peopl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"Florida is a state in the Southeastern regio...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>anyone question whether bundy-led right-wing t...</td>\n",
       "      <td>Bundy, Malheur National Wildlife Refuge, Amand...</td>\n",
       "      <td>Bundy: Theodore Robert Bundy (né Cowell; Novem...</td>\n",
       "      <td>Bundy: Theodore Robert Bundy (né Cowell; Novem...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>content : anyone question whether bundy-led ri...</td>\n",
       "      <td>[\"On January 2, 2016, an armed group of right-...</td>\n",
       "      <td>[\"This sentence supports the news because it f...</td>\n",
       "      <td>[\"On January 2, 2016, an armed group of right-...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  \\\n",
       "0             0           0   \n",
       "1             1           2   \n",
       "2             2           3   \n",
       "3             3           5   \n",
       "4             4           6   \n",
       "\n",
       "                                                news  \\\n",
       "0  u.s. senate republican leader mitch mcconnell ...   \n",
       "1  note little johnny might want consider use dia...   \n",
       "2  president obama is clearly in good spirits tha...   \n",
       "3  a racist white woman in florida is surely furi...   \n",
       "4  anyone question whether bundy-led right-wing t...   \n",
       "\n",
       "                                  extracted_entities  \\\n",
       "0  Mitch McConnell, Myanmar, Aung San Suu Kyi, Jo...   \n",
       "1  little johnny, isis, fort riley military base,...   \n",
       "2  president obama, republican party, trump presi...   \n",
       "3  Florida, Tallahassee, Trump, Martin Luther Kin...   \n",
       "4  Bundy, Malheur National Wildlife Refuge, Amand...   \n",
       "\n",
       "                                        wiki_summary  \\\n",
       "0  Mitch McConnell: Addison Mitchell McConnell II...   \n",
       "1  little johnny: Little Johnny jokes are about a...   \n",
       "2  president obama: Barack Hussein Obama II (born...   \n",
       "3  Florida: Florida (  FLORR-ih-də; Spanish: [flo...   \n",
       "4  Bundy: Theodore Robert Bundy (né Cowell; Novem...   \n",
       "\n",
       "                                           wiki_full  label  \\\n",
       "0  Mitch McConnell: Addison Mitchell McConnell II...      1   \n",
       "1  little johnny: Little Johnny jokes are about a...      1   \n",
       "2  president obama: Barack Hussein Obama II (born...      0   \n",
       "3  Florida: Florida (  FLORR-ih-də; Spanish: [flo...      0   \n",
       "4  Bundy: Theodore Robert Bundy (né Cowell; Novem...      1   \n",
       "\n",
       "                                               title  \\\n",
       "0  senate leader opposes lecturing myanmar leader...   \n",
       "1                                                NaN   \n",
       "2  president obama gets his troll game on by than...   \n",
       "3  racist florida woman tells black people you sh...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         news_merged  \\\n",
       "0  title : senate leader opposes lecturing myanma...   \n",
       "1  content : note little johnny might want consid...   \n",
       "2  title : president obama gets his troll game on...   \n",
       "3  title : racist florida woman tells black peopl...   \n",
       "4  content : anyone question whether bundy-led ri...   \n",
       "\n",
       "                                       key sentences  \\\n",
       "0  [\"Mitch McConnell said on Tuesday he would not...   \n",
       "1  [\"A 20-year-old Kansas man plotted to kill an ...   \n",
       "2  [\"Obama said it was crucial for voters to oppo...   \n",
       "3                                                 []   \n",
       "4  [\"On January 2, 2016, an armed group of right-...   \n",
       "\n",
       "                           key sentences explanation  \\\n",
       "0  [\"McConnell's opposition to the resolution dir...   \n",
       "1  [\"This sentence supports the news because it p...   \n",
       "2  [\"This sentence supports the news because it e...   \n",
       "3                                                 []   \n",
       "4  [\"This sentence supports the news because it f...   \n",
       "\n",
       "                       summarized evidence sentences  \\\n",
       "0  [\"Mitch McConnell is an American politician an...   \n",
       "1  [\"Little Johnny jokes are about a small boy wh...   \n",
       "2  [\"President Obama is the 44th president of the...   \n",
       "3  [\"Florida is a state in the Southeastern regio...   \n",
       "4  [\"On January 2, 2016, an armed group of right-...   \n",
       "\n",
       "                                 gold  \n",
       "0                 [2, 3, 8, 6, 9, 14]  \n",
       "1                    [13, 12, 29, 30]  \n",
       "2                         [13, 14, 4]  \n",
       "3                                  []  \n",
       "4  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_wiki = pd.read_csv('/kaggle/input/gold0303/labeled_gold_0302.csv')\n",
    "data_wiki.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T14:58:31.751507Z",
     "iopub.status.busy": "2025-03-03T14:58:31.751241Z",
     "iopub.status.idle": "2025-03-03T14:58:31.756631Z",
     "shell.execute_reply": "2025-03-03T14:58:31.755998Z",
     "shell.execute_reply.started": "2025-03-03T14:58:31.751487Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"Mitch McConnell is an American politician and the senior United States senator from Kentucky.\", \"He has served from 2007 to 2025 as the leader of the Senate Republican Conference.\", \"On Tuesday, McConnell stated he would not support a resolution targeting Myanmar leader Aung San Suu Kyi.\", \"He expressed that he does not favor a resolution going after her.\", \"McConnell has been engaged with Myanmar issues for years.\", \"He regards Aung San Suu Kyi as the greatest hope for Myanmar\\'s transition from military dictatorship.\", \"Senators John McCain and Richard Durbin introduced a resolution condemning violence against the Rohingya Muslims.\", \"McConnell expressed his disagreement with McCain and Durbin\\'s resolution.\", \"He commented that America lecturing Aung San Suu Kyi in her challenging position is unhelpful.\", \"International pressure on Myanmar has increased regarding the Rohingya Muslims\\' treatment.\", \"Approximately 370,000 Rohingya Muslims have fled to Bangladesh due to violence.\", \"The Trump administration has advocated for civilian protection in Myanmar.\", \"Bangladesh has requested safe zones for returning refugees.\", \"McConnell has been a supporter of Myanmar\\'s transition from military rule.\", \"Suu Kyi has faced criticism for a perceived lack of action against violence.\", \"John McCain has sought to eliminate U.S. military cooperation with Myanmar due to the humanitarian crisis.\", \"McConnell mentioned that he had hoped military cooperation could support reform in Burma.\", \"He can no longer support expanded military-to-military cooperation with Myanmar.\", \"The United States has had a longstanding history in Myanmar, especially regarding its military rule.\", \"The country has witnessed ethnic strife and ongoing human rights violations.\", \"Suu Kyi was a prominent figure in the struggle for democracy in Myanmar.\", \"Myanmar was a British colony and has experienced a troubled post-independence history.\", \"McConnell\\'s viewpoints show the complexity of U.S. foreign policy toward Myanmar.\", \"The situation in Myanmar remains a significant human rights issue globally.\", \"Criticism of Aung San Suu Kyi reflects the tensions between her government and the Rohingya crisis.\", \"The international community largely condemned the military coup in Myanmar.\", \"After the coup in February 2021, widespread protests erupted in Myanmar.\", \"Suu Kyi has faced numerous politically motivated charges since the coup.\", \"The military regained control after the 2020 election, which Suu Kyi\\'s party won decisively.\", \"Myanmar\\'s military has been accused of violent repression against civilians.\", \"The country\\'s ongoing conflict has created a severe humanitarian crisis.\"]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_wiki['summarized evidence sentences'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T14:58:38.988545Z",
     "iopub.status.busy": "2025-03-03T14:58:38.988237Z",
     "iopub.status.idle": "2025-03-03T14:58:38.994308Z",
     "shell.execute_reply": "2025-03-03T14:58:38.993408Z",
     "shell.execute_reply.started": "2025-03-03T14:58:38.988523Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "['Mitch McConnell is an American politician and the senior United States senator from Kentucky.', 'He has served from 2007 to 2025 as the leader of the Senate Republican Conference.', 'On Tuesday, McConnell stated he would not support a resolution targeting Myanmar leader Aung San Suu Kyi.', 'He expressed that he does not favor a resolution going after her.', 'McConnell has been engaged with Myanmar issues for years.', \"He regards Aung San Suu Kyi as the greatest hope for Myanmar's transition from military dictatorship.\", 'Senators John McCain and Richard Durbin introduced a resolution condemning violence against the Rohingya Muslims.', \"McConnell expressed his disagreement with McCain and Durbin's resolution.\", 'He commented that America lecturing Aung San Suu Kyi in her challenging position is unhelpful.', \"International pressure on Myanmar has increased regarding the Rohingya Muslims' treatment.\", 'Approximately 370,000 Rohingya Muslims have fled to Bangladesh due to violence.', 'The Trump administration has advocated for civilian protection in Myanmar.', 'Bangladesh has requested safe zones for returning refugees.', \"McConnell has been a supporter of Myanmar's transition from military rule.\", 'Suu Kyi has faced criticism for a perceived lack of action against violence.', 'John McCain has sought to eliminate U.S. military cooperation with Myanmar due to the humanitarian crisis.', 'McConnell mentioned that he had hoped military cooperation could support reform in Burma.', 'He can no longer support expanded military-to-military cooperation with Myanmar.', 'The United States has had a longstanding history in Myanmar, especially regarding its military rule.', 'The country has witnessed ethnic strife and ongoing human rights violations.', 'Suu Kyi was a prominent figure in the struggle for democracy in Myanmar.', 'Myanmar was a British colony and has experienced a troubled post-independence history.', \"McConnell's viewpoints show the complexity of U.S. foreign policy toward Myanmar.\", 'The situation in Myanmar remains a significant human rights issue globally.', 'Criticism of Aung San Suu Kyi reflects the tensions between her government and the Rohingya crisis.', 'The international community largely condemned the military coup in Myanmar.', 'After the coup in February 2021, widespread protests erupted in Myanmar.', 'Suu Kyi has faced numerous politically motivated charges since the coup.', \"The military regained control after the 2020 election, which Suu Kyi's party won decisively.\", \"Myanmar's military has been accused of violent repression against civilians.\", \"The country's ongoing conflict has created a severe humanitarian crisis.\"]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "s = data_wiki['summarized evidence sentences'][0]\n",
    "k = data_wiki['key sentences'][0]\n",
    "# 문자열을 리스트로 변환\n",
    "lsts = ast.literal_eval(s)\n",
    "lstk = ast.literal_eval(k)\n",
    "print(len(lsts))\n",
    "print(lsts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T14:58:42.751963Z",
     "iopub.status.busy": "2025-03-03T14:58:42.751655Z",
     "iopub.status.idle": "2025-03-03T14:58:42.871009Z",
     "shell.execute_reply": "2025-03-03T14:58:42.870308Z",
     "shell.execute_reply.started": "2025-03-03T14:58:42.751938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def strtolist(text):\n",
    "    lsti = ast.literal_eval(text)\n",
    "    return lsti\n",
    "\n",
    "data_wiki['gold'] = data_wiki['gold'].apply(strtolist)\n",
    "data_wiki['summarized evidence sentences'] = data_wiki['summarized evidence sentences'].apply(strtolist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bigbird -> MLP -> golden evidence 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T14:58:45.328036Z",
     "iopub.status.busy": "2025-03-03T14:58:45.327746Z",
     "iopub.status.idle": "2025-03-03T14:58:45.340738Z",
     "shell.execute_reply": "2025-03-03T14:58:45.339864Z",
     "shell.execute_reply.started": "2025-03-03T14:58:45.328015Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "max = 0\n",
    "for i in range(1385):\n",
    "    for j in data_wiki['gold'][i]:\n",
    "        if j > max:\n",
    "            max = j\n",
    "\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T14:58:48.138934Z",
     "iopub.status.busy": "2025-03-03T14:58:48.138423Z",
     "iopub.status.idle": "2025-03-03T14:58:48.207963Z",
     "shell.execute_reply": "2025-03-03T14:58:48.206604Z",
     "shell.execute_reply.started": "2025-03-03T14:58:48.138880Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T14:58:50.700806Z",
     "iopub.status.busy": "2025-03-03T14:58:50.700464Z",
     "iopub.status.idle": "2025-03-03T14:58:50.706898Z",
     "shell.execute_reply": "2025-03-03T14:58:50.706080Z",
     "shell.execute_reply.started": "2025-03-03T14:58:50.700778Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def format_evidence(evidence):\n",
    "    full_text_list = nltk.sent_tokenize(evidence)\n",
    "    \n",
    "    # 하나의 문자열로 합치기\n",
    "    full_text = ' '.join(full_text_list)\n",
    "\n",
    "    # 문장 분할 (NLTK 사용)\n",
    "    sentences = nltk.sent_tokenize(full_text)\n",
    "\n",
    "    # 너무 짧은 문장 제거 (5자 이하)\n",
    "    sentences = [s.strip() for s in sentences if len(s.strip()) > 5][:25]\n",
    "\n",
    "    # 빈 리스트 예외 처리\n",
    "    if not sentences:\n",
    "        return ''\n",
    "\n",
    "    # [SEP] 추가하여 하나의 문자열로 변환\n",
    "    return ' [SEP] '.join(sentences) + ' [SEP] '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T14:58:53.662902Z",
     "iopub.status.busy": "2025-03-03T14:58:53.662526Z",
     "iopub.status.idle": "2025-03-03T14:58:53.667082Z",
     "shell.execute_reply": "2025-03-03T14:58:53.666379Z",
     "shell.execute_reply.started": "2025-03-03T14:58:53.662876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#claims\n",
    "claims = []\n",
    "for a in data_wiki['news']:\n",
    "    claims.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T14:58:55.912389Z",
     "iopub.status.busy": "2025-03-03T14:58:55.912100Z",
     "iopub.status.idle": "2025-03-03T14:58:55.982692Z",
     "shell.execute_reply": "2025-03-03T14:58:55.981880Z",
     "shell.execute_reply.started": "2025-03-03T14:58:55.912367Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>evidences</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[Mitch McConnell is an American politician and...</td>\n",
       "      <td>[CLS] u.s. senate republican leader mitch mcc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...</td>\n",
       "      <td>[Little Johnny jokes are about a small boy who...</td>\n",
       "      <td>[CLS] note little johnny might want consider ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>[President Obama is the 44th president of the ...</td>\n",
       "      <td>[CLS] president obama is clearly in good spir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Florida is a state in the Southeastern region...</td>\n",
       "      <td>[CLS] a racist white woman in florida is sure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[On January 2, 2016, an armed group of right-w...</td>\n",
       "      <td>[CLS] anyone question whether bundy-led right...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[Donald John Trump is an American politician a...</td>\n",
       "      <td>[CLS] washington u.s. senate expect vote 11 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...</td>\n",
       "      <td>[The Federal Bureau of Investigation (FBI) is ...</td>\n",
       "      <td>[CLS] this is huge! the doj has authorized th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Paul Ryan is an American politician who serve...</td>\n",
       "      <td>[CLS] washington u.s. house speaker paul ryan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>[Dinesh D'Souza warned about Obama's reduction...</td>\n",
       "      <td>[CLS] dinesh d sousa warned us about obama s ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Muhammed Fethullah Gülen was a Turkish Muslim...</td>\n",
       "      <td>[CLS] turkish and sudanese intelligence agenc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1386 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  label  \\\n",
       "0     [0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...   \n",
       "2     [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "1381  [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "1382  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...   \n",
       "1383  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1384  [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, ...   \n",
       "1385  [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                              evidences  \\\n",
       "0     [Mitch McConnell is an American politician and...   \n",
       "1     [Little Johnny jokes are about a small boy who...   \n",
       "2     [President Obama is the 44th president of the ...   \n",
       "3     [Florida is a state in the Southeastern region...   \n",
       "4     [On January 2, 2016, an armed group of right-w...   \n",
       "...                                                 ...   \n",
       "1381  [Donald John Trump is an American politician a...   \n",
       "1382  [The Federal Bureau of Investigation (FBI) is ...   \n",
       "1383  [Paul Ryan is an American politician who serve...   \n",
       "1384  [Dinesh D'Souza warned about Obama's reduction...   \n",
       "1385  [Muhammed Fethullah Gülen was a Turkish Muslim...   \n",
       "\n",
       "                                              sentences  \n",
       "0      [CLS] u.s. senate republican leader mitch mcc...  \n",
       "1      [CLS] note little johnny might want consider ...  \n",
       "2      [CLS] president obama is clearly in good spir...  \n",
       "3      [CLS] a racist white woman in florida is sure...  \n",
       "4      [CLS] anyone question whether bundy-led right...  \n",
       "...                                                 ...  \n",
       "1381   [CLS] washington u.s. senate expect vote 11 a...  \n",
       "1382   [CLS] this is huge! the doj has authorized th...  \n",
       "1383   [CLS] washington u.s. house speaker paul ryan...  \n",
       "1384   [CLS] dinesh d sousa warned us about obama s ...  \n",
       "1385   [CLS] turkish and sudanese intelligence agenc...  \n",
       "\n",
       "[1386 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import random\n",
    "\n",
    "gold_evidence_mask = []\n",
    "\n",
    "def to_one(size, indices):\n",
    "    return [1 if i in indices else 0 for i in range(size)]\n",
    "\n",
    "for i in range(len(data_wiki['gold'])):\n",
    "    gold_evidence_mask.append(to_one(40,data_wiki['gold'][i]))\n",
    "\n",
    "\n",
    "\n",
    "sentences = []                                                     #판별할 문장\n",
    "for claim, evidence in zip(claims, data_wiki['summarized evidence sentences']):\n",
    "    sentence = f\" [CLS] {claim} [SEP] {evidence} [SEP]\"\n",
    "    sentences.append(sentence)\n",
    "\n",
    "\n",
    "data = pd.DataFrame(sentences, columns=[\"label\"]) # [CLS] claim [SEP] evidence [SEP]\n",
    "data['label'] = gold_evidence_mask # 정답 Gold evidence들의 top 5 indices\n",
    "data['evidences'] = data_wiki['summarized evidence sentences']\n",
    "data['sentences'] = sentences\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T14:59:03.077716Z",
     "iopub.status.busy": "2025-03-03T14:59:03.077367Z",
     "iopub.status.idle": "2025-03-03T14:59:03.088066Z",
     "shell.execute_reply": "2025-03-03T14:59:03.087137Z",
     "shell.execute_reply.started": "2025-03-03T14:59:03.077690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#train for sentence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_text, temp_text, train_label, temp_label = train_test_split(data['sentences'], data['label'],\n",
    "                                                                  test_size=0.3,\n",
    "                                                                  random_state=2018\n",
    "                                                                  )\n",
    "\n",
    "val_text, test_text, val_label, test_label = train_test_split(temp_text, temp_label,\n",
    "                                                                  test_size=0.5,\n",
    "                                                                  random_state=2018\n",
    "                                                                  )\n",
    "\n",
    "print_text, _, print_label, _ = train_test_split(temp_text, temp_label,\n",
    "                                                test_size=0.99,\n",
    "                                                random_state=2018\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T14:59:13.224009Z",
     "iopub.status.busy": "2025-03-03T14:59:13.223698Z",
     "iopub.status.idle": "2025-03-03T14:59:13.228849Z",
     "shell.execute_reply": "2025-03-03T14:59:13.227967Z",
     "shell.execute_reply.started": "2025-03-03T14:59:13.223985Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 953,   36, 1150,  401,  167, 1365,  324,  305,  190,  910,\n",
      "       ...\n",
      "         87,  537,  902,  148, 1180,  917,  777,  226,  614, 1274],\n",
      "      dtype='int64', length=970)\n"
     ]
    }
   ],
   "source": [
    "print(train_text.index) #Loss function에 사용될 실제 데이터 index들."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#model2\n",
    "class NewsVerificationModel(nn.Module):\n",
    "    def __init__(self, model_name=\"google/bigbird-roberta-base\", freeze_bert=False):\n",
    "        \"\"\"\n",
    "        뉴스 진위여부 판별 모델 (Cross Attention 활용)\n",
    "        Args:\n",
    "            model_name: 사용할 사전학습 언어모델 이름\n",
    "            freeze_bert: 언어모델 파라미터 동결 여부\n",
    "        \"\"\"\n",
    "        super(NewsVerificationModel, self).__init__()\n",
    "\n",
    "        # (1) 언어모델\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "\n",
    "        # (2) 동결 설정\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # (3) 문장 레벨 어텐션\n",
    "        self.sentence_attention = SentenceWiseAttention(self.hidden_size)\n",
    "\n",
    "        # (4) 뉴스-문서 Cross Attention\n",
    "        self.cross_attention = nn.MultiheadAttention(\n",
    "            embed_dim=self.hidden_size,\n",
    "            num_heads=8,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # (5) 최종 분류기\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size * 2, 256),  # (뉴스CLS + 문서임베딩)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 2)  # (진실 / 거짓)\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "                news_input_ids, news_attention_mask,\n",
    "                doc_sentences_input_ids, doc_sentences_attention_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            news_input_ids: (batch_size, news_len)\n",
    "            news_attention_mask: (batch_size, news_len)\n",
    "            doc_sentences_input_ids: (batch_size, num_sentences, sentence_len)\n",
    "            doc_sentences_attention_mask: (batch_size, num_sentences, sentence_len)\n",
    "        Returns:\n",
    "            logits: (batch_size, 2)\n",
    "            sentences_attention_weights: (batch_size, num_sentences)\n",
    "        \"\"\"\n",
    "        device = news_input_ids.device\n",
    "        batch_size, num_sentences, sent_len = doc_sentences_input_ids.shape\n",
    "\n",
    "        # ---------------------\n",
    "        # 1) 뉴스 인코딩\n",
    "        # ---------------------\n",
    "        news_outputs = self.bert(\n",
    "            news_input_ids,\n",
    "            attention_mask=news_attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        # 전체 임베딩 (batch_size, news_len, hidden_size)\n",
    "        news_emb = news_outputs.last_hidden_state\n",
    "        # 뉴스 CLS (batch_size, hidden_size)\n",
    "        news_cls = news_emb[:, 0, :]\n",
    "\n",
    "        # ---------------------\n",
    "        # 2) 문서 문장 인코딩\n",
    "        # ---------------------\n",
    "        # Flatten\n",
    "        flattened_ids = doc_sentences_input_ids.view(-1, sent_len)           # (batch_size * num_sentences, sentence_len)\n",
    "        flattened_mask = doc_sentences_attention_mask.view(-1, sent_len)     # 동일 크기\n",
    "\n",
    "        valid_sent_mask = flattened_mask.sum(dim=1) > 0\n",
    "        all_embeddings = torch.zeros(\n",
    "            (batch_size * num_sentences, self.hidden_size),\n",
    "            device=device\n",
    "        )\n",
    "        if valid_sent_mask.sum() > 0:\n",
    "            valid_ids = flattened_ids[valid_sent_mask]\n",
    "            valid_mask = flattened_mask[valid_sent_mask]\n",
    "\n",
    "            valid_out = self.bert(\n",
    "                valid_ids,\n",
    "                attention_mask=valid_mask,\n",
    "                return_dict=True\n",
    "            )\n",
    "            # (유효 문장의 CLS)\n",
    "            valid_cls = valid_out.last_hidden_state[:, 0, :]\n",
    "            all_embeddings[valid_sent_mask] = valid_cls\n",
    "\n",
    "        # 다시 (batch_size, num_sentences, hidden_size) 형태로 복원\n",
    "        sentence_embeddings = all_embeddings.view(batch_size, num_sentences, self.hidden_size)\n",
    "\n",
    "        # ---------------------\n",
    "        # 3) Cross Attention\n",
    "        # ---------------------\n",
    "        # Query: sentence_embeddings\n",
    "        # Key, Value: news_emb\n",
    "        # key_padding_mask는 True가 '무시할 위치' 이므로\n",
    "        # news_attention_mask: 1=사용,0=패딩 => ~news_attention_mask.bool()\n",
    "\n",
    "        key_padding_mask = ~news_attention_mask.bool()  # shape: (batch_size, news_len)\n",
    "\n",
    "        cross_attn_out, _ = self.cross_attention(\n",
    "            query=sentence_embeddings,         # (batch_size, num_sentences, hidden_size)\n",
    "            key=news_emb,                      # (batch_size, news_len, hidden_size)\n",
    "            value=news_emb,                    # (batch_size, news_len, hidden_size)\n",
    "            key_padding_mask=key_padding_mask, # (batch_size, news_len)\n",
    "            need_weights=False\n",
    "        )\n",
    "        # cross_attn_out: (batch_size, num_sentences, hidden_size)\n",
    "\n",
    "        # ---------------------\n",
    "        # 4) 문장별 어텐션\n",
    "        # ---------------------\n",
    "        # (batch_size, num_sentences)\n",
    "        sentence_exists_mask = (doc_sentences_attention_mask.sum(dim=2) > 0)\n",
    "\n",
    "        doc_embedding, sentences_attention_weights = self.sentence_attention(\n",
    "            cross_attn_out,\n",
    "            attention_mask=sentence_exists_mask\n",
    "        ) # 가중합 반환\n",
    "\n",
    "        # ---------------------\n",
    "        # 5) 최종 분류\n",
    "        # ---------------------\n",
    "        combined = torch.cat([news_cls, doc_embedding], dim=1)  # (batch_size, hidden_size*2)\n",
    "        logits = self.classifier(combined)                      # (batch_size, 2)\n",
    "\n",
    "        return logits, sentences_attention_weights\n",
    "\n",
    "model2 = NewsVerificationModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T14:59:49.092944Z",
     "iopub.status.busy": "2025-03-03T14:59:49.092576Z",
     "iopub.status.idle": "2025-03-03T14:59:49.101090Z",
     "shell.execute_reply": "2025-03-03T14:59:49.100330Z",
     "shell.execute_reply.started": "2025-03-03T14:59:49.092915Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#claim & gold evidence labels (claim은 안쓰임 이미 sentence에 들어갔기 때문에)\n",
    "train_claim, temp_claim, train_label, temp_label = train_test_split(data_wiki['news'], data['label'],\n",
    "                                                                  test_size=0.3,\n",
    "                                                                  random_state=2018\n",
    "                                                                  )\n",
    "val_claim, test_claim, val_label, test_label = train_test_split(temp_claim, temp_label,\n",
    "                                                                  test_size=0.5,\n",
    "                                                                  random_state=2018\n",
    "                                                                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T14:59:49.534758Z",
     "iopub.status.busy": "2025-03-03T14:59:49.534406Z",
     "iopub.status.idle": "2025-03-03T14:59:49.542764Z",
     "shell.execute_reply": "2025-03-03T14:59:49.541975Z",
     "shell.execute_reply.started": "2025-03-03T14:59:49.534727Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_evidence, temp_evidence, train_nothing, temp_nothing = train_test_split(data_wiki['wiki_summary'], data['label'],\n",
    "                                                                              test_size=0.3,\n",
    "                                                                              random_state=2018)\n",
    "val_evidence, test_evidence, nothing1, nothing2 = train_test_split(temp_evidence, temp_nothing,\n",
    "                                                                              test_size=0.5,\n",
    "                                                                              random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T14:59:58.976020Z",
     "iopub.status.busy": "2025-03-03T14:59:58.975681Z",
     "iopub.status.idle": "2025-03-03T14:59:58.982008Z",
     "shell.execute_reply": "2025-03-03T14:59:58.981247Z",
     "shell.execute_reply.started": "2025-03-03T14:59:58.975991Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#학습 데이터 로딩\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class FakeNewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=4096):\n",
    "        self.sending = texts.index\n",
    "        self.texts = texts.tolist()  # Claim + Evidence\n",
    "        self.labels = labels.tolist()  # 50개의 0과 1 벡터\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "         \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx], \n",
    "            padding=\"max_length\",\n",
    "            truncation=True, \n",
    "            max_length=self.max_length, \n",
    "            return_tensors=\"pt\",\n",
    "            add_special_tokens=True,\n",
    "        )\n",
    "        input_ids = encoding[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = encoding[\"attention_mask\"].squeeze(0)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        k = self.sending[idx] # Loss function에 갖다줄 index\n",
    "\n",
    "        return input_ids, attention_mask, label, k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T15:33:54.846676Z",
     "iopub.status.busy": "2025-03-03T15:33:54.846320Z",
     "iopub.status.idle": "2025-03-03T15:33:55.260309Z",
     "shell.execute_reply": "2025-03-03T15:33:55.259609Z",
     "shell.execute_reply.started": "2025-03-03T15:33:54.846644Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = BigBirdTokenizer.from_pretrained(\"google/bigbird-roberta-base\")\n",
    "\n",
    "train_dataset = FakeNewsDataset(train_text, train_label, tokenizer)\n",
    "val_dataset = FakeNewsDataset(val_text, val_label, tokenizer)\n",
    "test_dataset = FakeNewsDataset(test_text, test_label, tokenizer)\n",
    "print_dataset = FakeNewsDataset(print_text, print_label, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T15:00:07.367445Z",
     "iopub.status.busy": "2025-03-03T15:00:07.367115Z",
     "iopub.status.idle": "2025-03-03T15:00:07.773123Z",
     "shell.execute_reply": "2025-03-03T15:00:07.772202Z",
     "shell.execute_reply.started": "2025-03-03T15:00:07.367417Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "gc.collect()  # Python의 가비지 컬렉션 실행\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T15:00:19.914496Z",
     "iopub.status.busy": "2025-03-03T15:00:19.914210Z",
     "iopub.status.idle": "2025-03-03T15:00:19.921076Z",
     "shell.execute_reply": "2025-03-03T15:00:19.920355Z",
     "shell.execute_reply.started": "2025-03-03T15:00:19.914475Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Model 1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BigBirdModel\n",
    "\n",
    "class BigBirdWithMLP(nn.Module):\n",
    "    def __init__(self, model_name=\"google/bigbird-roberta-base\", output_size=40, freeze_bigbird=False):\n",
    "        super(BigBirdWithMLP, self).__init__()\n",
    "        self.bigbird = BigBirdModel.from_pretrained(model_name, attention_type=\"block_sparse\")\n",
    "        self.hidden_size = self.bigbird.config.hidden_size  # 768\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(768, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(128),  # ✅ 속도 최적화\n",
    "            nn.Dropout(0.2),  # ✅ 과적합 방지\n",
    "            nn.Linear(128, 40),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bigbird(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_token = outputs.last_hidden_state[:, 0, :]  # [CLS] 토큰 추출\n",
    "        logits = self.mlp(cls_token)  # MLP 통과\n",
    "        return logits  # (batch_size, 40) → 확률값이 아니라 logits 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T15:00:23.386964Z",
     "iopub.status.busy": "2025-03-03T15:00:23.386657Z",
     "iopub.status.idle": "2025-03-03T15:00:23.396192Z",
     "shell.execute_reply": "2025-03-03T15:00:23.395423Z",
     "shell.execute_reply.started": "2025-03-03T15:00:23.386942Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Loss_fullness, Loss_sufficiency를 반영한 Loss function (ReRead 논문)\n",
    "class CustomSentenceRemovalLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomSentenceRemovalLoss, self).__init__()\n",
    "\n",
    "    def forward(self, predictions, targets, input_ids, attention_masks, indices):\n",
    "        \"\"\"\n",
    "        predictions: 모델의 출력 (0~1 확률값, batch_size x 50)\n",
    "        targets: 정답 라벨 (0 또는 1, batch_size x 50)\n",
    "        \"\"\"\n",
    "        loss = 0\n",
    "        final_loss = 0\n",
    "\n",
    "        size = len(predictions) #batch의 크기\n",
    "\n",
    "        for i in range(size):\n",
    "            with torch.no_grad():\n",
    "                outputs = model2(input_ids=input_ids[i].unsqueeze(0).to(device), \n",
    "                                attention_mask=attention_masks[i].unsqueeze(0).to(device))\n",
    "                probs = torch.sigmoid(outputs.logits)\n",
    "                og_value = data_wiki['label'].iloc[indices[i].item()] # 아무 조작도 가하지 않은 문장의 pure 예측\n",
    "    \n",
    "                del outputs\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                top5_indices = torch.topk(predictions[i], 5).indices #Model 1 이 예측한 evidence 문서안의 top 5 index\n",
    "                top5_indices = set(top5_indices.tolist())\n",
    "                evidences = data['evidences'].iloc[indices[i].item()] # evidence 문서를 아까 각 문장으로 쪼개놓았는데, 2D list에서 가져온 evidence 문서\n",
    "                                                                      # 여기서 아까 FakeNewsDataset의 k값이 사용되는 것임\n",
    "        \n",
    "                fullness_sentence = \" \".join([evidences[i] for i in range(len(evidences)) if i not in top5_indices]) # 예측한 top 5를 뺀문장\n",
    "                suff_sentence = \" \".join([evidences[i] for i in range(len(evidences)) if i in top5_indices]) # 예측한 top 5만 있는문장\n",
    "        \n",
    "                inputs = tokenizer(fullness_sentence, padding=\"max_length\", truncation=True, max_length=4096, return_tensors=\"pt\").to(device)\n",
    "                outputs = model2(**inputs)\n",
    "                probs = torch.sigmoid(outputs.logits)\n",
    "                fullness_value = probs[0, 1].item()\n",
    "                \n",
    "                del outputs\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                inputs = tokenizer(suff_sentence, padding=\"max_length\", truncation=True, max_length=4096, return_tensors=\"pt\").to(device)\n",
    "                outputs = model2(**inputs)\n",
    "                probs = torch.sigmoid(outputs.logits)\n",
    "                suff_value = probs[0, 1].item()\n",
    "    \n",
    "                del outputs \n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                # 그 두개의 문장으로 얻은 두가지 Loss(fullness, sufficiency)\n",
    "                Loss_fullness = abs(og_value - fullness_value)\n",
    "                Loss_suff = abs(og_value - suff_value)\n",
    "\n",
    "                # fullness는 클수록 좋기 때문에 -를 붙이고, suff는 작을수록 좋기 때문에 + -> 최종 loss값은 작아야 좋다는 일관성 확보\n",
    "                loss = - Loss_fullness + Loss_suff\n",
    "                final_loss += loss\n",
    "                \n",
    "\n",
    "        final_loss = torch.tensor(final_loss, requires_grad=True, device=\"cuda\")\n",
    "        return final_loss/size #loss의 평균값 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # ✅ 학습 함수 without full suff loss\n",
    "# def train(model, train_loader, val_loader, optimizer, criterion, epochs=30, device=\"cuda\"):\n",
    "#     model.to(device)\n",
    "\n",
    "#     best_loss = float(\"inf\")\n",
    "#     best_model_path = \"/kaggle/working/best_model.pt\"\n",
    "    \n",
    "#     for epoch in range(epochs):\n",
    "#         model.train()\n",
    "#         total_loss = 0\n",
    "        \n",
    "#         for batch in tqdm(train_loader):\n",
    "#             input_ids, attention_mask, labels, _ = [x.to(device) for x in batch]\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(input_ids, attention_mask)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             total_loss += loss.item()\n",
    "        \n",
    "#         avg_train_loss = total_loss / len(train_loader)\n",
    "#         print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}\")\n",
    "        \n",
    "#         # Validation\n",
    "#         model.eval()\n",
    "#         total_val_loss = 0\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 input_ids, attention_mask, labels, _ = [x.to(device) for x in batch]\n",
    "#                 outputs = model(input_ids, attention_mask)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "#                 total_val_loss += loss.item()\n",
    "\n",
    "        \n",
    "#         avg_val_loss = total_val_loss / len(val_loader)\n",
    "#         print(f\"Epoch {epoch+1}: Validation Loss = {avg_val_loss:.4f}\")\n",
    "\n",
    "#         if avg_val_loss < best_loss:\n",
    "#                             best_loss = avg_val_loss\n",
    "#                             torch.save(model.state_dict(), best_model_path)\n",
    "#                             print(f\"✅ Best Model Saved at {best_model_path} (Loss: {best_loss:.4f})\")\n",
    "\n",
    "# # ✅ 데이터 로드 및 학습 실행\n",
    "# tokenizer = BigBirdTokenizer.from_pretrained(\"google/bigbird-roberta-base\")\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# # 모델 및 옵티마이저 설정\n",
    "# model = BigBirdWithMLP()\n",
    "# optimizer = torch.optim.AdamW([\n",
    "#     {\"params\": model.bigbird.parameters(), \"lr\": 2e-5},  # BigBird는 작은 lr\n",
    "#     {\"params\": model.mlp.parameters(), \"lr\": 1e-3}  # MLP는 큰 lr\n",
    "# ])\n",
    "# criterion = CustomSentenceRemovalLoss()\n",
    "\n",
    "# # 학습 실행\n",
    "# train(model, train_loader, val_loader, optimizer, criterion, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T15:41:22.898288Z",
     "iopub.status.busy": "2025-03-03T15:41:22.897991Z",
     "iopub.status.idle": "2025-03-03T15:42:06.742628Z",
     "shell.execute_reply": "2025-03-03T15:42:06.741653Z",
     "shell.execute_reply.started": "2025-03-03T15:41:22.898267Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3e772814d94ef78905876f29f354fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.0247 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model.eval()\n",
    "total_test_loss = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        input_ids, attention_mask, labels, _ = [x.to(device) for x in batch]\n",
    "        \n",
    "        # 모델 예측값 (logits)\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        \n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_test_loss += loss.item()\n",
    "\n",
    "        # ✅ Sigmoid 적용 후 0.5 기준으로 예측 변환\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).int()\n",
    "        \n",
    "        # 리스트에 저장 (CPU로 변환)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 평균 Loss 계산\n",
    "avg_test_loss = total_test_loss / len(test_loader)\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T14:08:22.512562Z",
     "iopub.status.busy": "2025-03-03T14:08:22.512207Z",
     "iopub.status.idle": "2025-03-03T14:08:22.517174Z",
     "shell.execute_reply": "2025-03-03T14:08:22.516424Z",
     "shell.execute_reply.started": "2025-03-03T14:08:22.512532Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def highlight_indices(lst, highlight_idxs, color=\"\\033[91m\"):  # 91 = 빨간색\n",
    "    reset = \"\\033[0m\"  # 색상 초기화\n",
    "    result = []\n",
    "    \n",
    "    for i, val in enumerate(lst):\n",
    "        if i in highlight_idxs:\n",
    "            result.append(f\"{color}{val}{reset}\")  # 특정 인덱스 색상 적용\n",
    "        else:\n",
    "            result.append(str(val))\n",
    "    \n",
    "    print(\"[\" + \", \".join(result) + \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loss_fullness & Loss_efficiency\n",
    "def train(model, train_loader, val_loader, optimizer, criterion, epochs=3, device=\"cuda\"):\n",
    "    model.to(device)\n",
    "    for param in model.bigbird.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()        \n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in tqdm(train_loader):\n",
    "            input_ids, attention_mask, labels, indices = [x.to(device) for x in batch]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels, input_ids,attention_mask, indices)# 여기서 Input_ids랑 indices를 lossfunction에게 전달해서 사용할 수 있게끔\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}\")\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids, attention_mask, labels, indices = [x.to(device) for x in batch]\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                loss = criterion(outputs, labels, input_ids,attention_mask, indices)\n",
    "                total_val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        print(f\"Epoch {epoch+1}: Validation Loss = {avg_val_loss:.4f}\")\n",
    "\n",
    "        if avg_val_loss < best_loss:\n",
    "                    best_loss = avg_val_loss\n",
    "                    torch.save(model.state_dict(), best_model_path)\n",
    "                    print(f\"✅ Best Model Saved at {best_model_path} (Loss: {best_loss:.4f})\")\n",
    "\n",
    "# ✅ 데이터 로드 및 학습 실행\n",
    "tokenizer = BigBirdTokenizer.from_pretrained(\"google/bigbird-roberta-base\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=10, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "# 모델 및 옵티마이저 설정\n",
    "model = BigBirdWithMLP()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = 0.7 * CustomSentenceRemovalLoss() + 0.3 * nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 학습 실행\n",
    "train(model, train_loader, val_loader, optimizer, criterion, epochs=3)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6765418,
     "sourceId": 10887455,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6771280,
     "sourceId": 10895873,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6775532,
     "sourceId": 10901811,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
